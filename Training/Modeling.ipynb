{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wannakadee-Generator-CLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM,pipeline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"tupleblog/generate-thai-lyrics\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"tupleblog/generate-thai-lyrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WannakadeeDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, max_length):\n",
    "        self.file_path = file_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.lines = []\n",
    "        with open(self.file_path, 'r', encoding='utf-8') as f:\n",
    "            cur = \"\"\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    if(line[0]==\"๏\"):\n",
    "                        self.lines.append(cur)\n",
    "                        cur = \"\"\n",
    "                    cur += line + \" \\n \"\n",
    "                else:\n",
    "                    lines.append(cur + line + \" \\n \")\n",
    "        self.lines = self.lines[1:]        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        line = self.lines[idx]\n",
    "        encoded = self.tokenizer.encode_plus(\n",
    "            line,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = encoded['input_ids'].squeeze()\n",
    "        attention_mask = encoded['attention_mask'].squeeze()\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WannakadeeDataset(\"Dataset/phra_aphai-train.txt\", tokenizer, max_length=400)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_dataset = WannakadeeDataset(\"Dataset/phra_aphai-val.txt\", tokenizer, max_length=400)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = input_ids.clone().detach()\n",
    "        labels[labels == tokenizer.pad_token_id] = -100\n",
    "        output = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = output.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0\n",
    "    for batch in tqdm(valid_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = input_ids.clone().detach()\n",
    "        labels[labels == tokenizer.pad_token_id] = -100\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = output.loss\n",
    "        valid_loss += loss.item()\n",
    "    valid_loss /= len(valid_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Valid Loss: {valid_loss:.4f}')\n",
    "\n",
    "model.save_pretrained(\"model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = pipeline(\"text-generation\",model=model,tokenizer=tokenizer)    \n",
    "text = \"๏ สัมผัสเส้นขอบฟ้าชลาลัย\"\n",
    "generated_text = nlp(text,max_length=140,top_k=25,temperature=1)\n",
    "print(f\"Input: {text}\")\n",
    "print(f\"Output:\\n {generated_text[0]['generated_text']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
